{
  "paper_id": "12",
  "paper_title": "Evaluating Lexical Aspect with Large Language Models",
  "sections": [
    {
      "section": "FrontMatter",
      "chunks": [
        "Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics, pages 123–131 August 15, 2024 ©2024 Association for Computational Linguistics Evaluating Lexical Aspect with Large Language Models Bolei Ma LMU Munich & Munich Center for Machine Learning bolei.ma@lmu.de"
      ]
    },
    {
      "section": "Abstract",
      "chunks": [
        "In this study, we explore the proficiency of large language models (LLMs) in understanding two key lexical aspects: duration (durative/stative) and telicity (telic/atelic). Through experiments on datasets featuring sentences, verbs, and verb positions, we prompt the LLMs to identify aspectual features of verbs in sentences. Our findings reveal that certain LLMs, particularly those closed-source ones, are able to capture information on duration and telicity, albeit with some performance variations and weaker results compared to the baseline. By employing prompts at three levels (sentence-only, sentence with verb, and sentence with verb and its position), we demonstrate that integrating verb information generally enhances performance in aspectual feature recognition, though it introduces instability. We call for future research to look deeper into methods aimed at optimizing LLMs for aspectual feature comprehension. 1"
      ]
    },
    {
      "section": "Introduction",
      "chunks": [
        "Aspect is a verbal category that is closely linked to concepts such as tense, temporality, verbal semantics, and quantification. In linguistics, aspect refers to different perspectives on the internal temporal constitution of a situation (Comrie, 1976; Leiss, 1992; Klein, 1994; Xiao and McEnery, 2004). There is two main sub groups of aspect, the grammatical aspect which refers to the verbal flexion in languages such as Slavic Languages, and the lexical aspect which contains the semantics of the event or state of a verb phrase situated in time. In this paper, we focus on the lexical aspect with two important aspect features: duration and telicity. Duration (durative/stative) is the property of a verb or verb phrase that presents a state or an action, regardless of their endpoints. Durative aspect denotes the reading of an action, while stative aspect denotes the reading of a state. Telicity (telic/atelic) distinguishes between verbs that describe an action Label Sentence durative The boxer is hitting his opponent. stative Bread consists of flour, water and yeast. telic I ate a fish for lunch. atelic Cork floats on water. Table 1: Examples of the two aspect features: duration (durative/stative) and telicity (telic/atelic) (Metheniti et al., 2022). or event as having a specific endpoint. Telic aspect denotes the reading of the endpoint of an action or event, while atelic aspect denotes the reading of no endpoint. Table 1 shows examples for each feature in English. The identification of the aspectual features of the verbs in the sentence could be difficult as other verb categories or sentence elements such as tense, temporal adverbials, and context could affect the reading of the aspect (Zhang, 1995). Using computational models to identify the aspectual features could be therefore more challenging. There are various existing works on building datasets for lexical aspect and training models to classify the sentences in terms of their aspectual features (Friedrich and Palmer, 2014; Friedrich and Pinkal, 2015; Friedrich et al., 2016; Friedrich and Gateva, 2017; Kober et al., 2020; Metheniti et al., 2022). Nowadays, the vast expanse of LLMs has also opened the chance to study linguistics using LLMs (Opitz et al., 2024). Therefore, it is interesting to probe the proficiency of LLMs on aspectual features. In this paper, based on a dataset on duration and telicity (Metheniti et al., 2022), we evaluate the ability of 6 different LLMs to identify the two aspectual features of sentences by zero-shot prompting the LLMs in three different levels: sentenceonly, sentence with verb, and sentence with verb and its position. Our experimental results show that some LLMs are capable of capturing aspectual information, while there are some variations and 123 weaker performance compared to the fine-tuning baseline. In addition, adding verb information generally improves the prediction performance of LLMs.",
        "Overall, our study provides valuable insights into the challenges and opportunities in leveraging LLMs for evaluating lexical aspect. 2"
      ]
    },
    {
      "section": "Related Work",
      "chunks": [
        "The evaluation and classification of aspectual features of verbs using NLP have been explored extensively in previous research. Siegel and McKeown (2000) are the first to employ supervised machine learning methods for aspectual classification. Friedrich and Palmer (2014) introduced a semisupervised approach that combined linguistic and distributional features to predict a verb’s stativity/duration, also providing two annotated datasets for stativity. Furthermore, Friedrich and Pinkal (2015) focused on classifying clauses based on their aspectual properties, and expanded the scope to include situation entity types in Friedrich et al. (2016). Friedrich and Gateva (2017) contributed two English datasets with gold and silver annotations of telicity and duration, utilizing an L1regularized multi-class logistic regression model. Hermes et al. (2015) computationally modeled Vendler classes (Vendler, 1957) for 95 German verbs, combining distributional vectors with supervised classification. Additionally, Ramm et al. (2017) developed the first open-source tool for annotating morphosyntactic tense, mood, and voice for verbal complexes in multiple languages. Kober et al. (2020) introduced a dataset for tense and aspect concepts using natural language inference and proposed modeling aspect of English verbs in context using compositional distributional models. In a more recent study by using a bunch of transformer-based models, Metheniti et al. (2022) conducted experiments on transformer models to identify aspectual features, revealing biases towards verb tense and word order. However, in the current era of the advances of LLMs, it is still unexplored whether the LLMs are able to capture the aspectual features. A more detailed introduction to aspect concepts and their computational approaches can be found in this survey (Friedrich et al., 2023). 3"
      ]
    },
    {
      "section": "Experiments",
      "chunks": [
        "Dataset. We use the dataset with telicity and duration-annotated sentences created by Metheniti et al. (2022). The dataset was built upon two previous datasets from Friedrich and Gateva (2017) and Alikhani and Stone (2019). It has two main subsets, one for duration and the other for telicity. Each subset contains sentences with the main verbs and their positions in sentences, as well as binary labels for durative (‘1’) or stative aspect (‘0’) in the duration subset, and telic (‘1’) or atelic (‘0’) aspect in the telicity subset. The label distribution in the test sets is presented in §A.1. Prompt. Each question consists of a general instruction with a choice of answers (e.g. durative or stative) and the example sentence. We include the sentence, verb and verb information into the prompt. In addition, to test the robustness of the models as well as the ability of the models to comprehend the aspectual features both in the sentence level (without explicitly mentioning the verb) and the verb level (with explicitly mentioning the verb), we conduct the experiments in three different levels with different prompt formats. Table 2 shows the prompt formats of the three levels in the examples of duration subset with durative and stative aspects. In level 1, we only provide the sentence and ask for the aspect features. In level 2, we include the verb into the prompt. In level 3, we include the verb along with its position in the sentence into the prompt. The prompts are outlined in Table 2. Models. We evaluate the aspect tasks with the following close- and open-source instruction-tuned LLMs: GPT-3.5 (Brown et al., 2020) and GPT-4 (OpenAI et al., 2024), Llama-2-13b-chat-hf and Meta-Llama-3-8B-Instruct (Touvron et al., 2023), Gemma-7b-it (Team et al., 2024), and Mixtral-8x7B-Instruct-v0.1 (Jiang et al., 2024). Baseline. We compare our zero-shot prompting of LLMs with the baselines of fine-tuning BERTbased models (Devlin et al., 2019) on the training data with and without adding information on the verb position as in Metheniti et al. (2022). We select the best performing model bert-large-cased in their work for fine-tuning as baseline. LLM Output Extraction. Although we prompt the LLMs to give answers with single tokens of telic/atelic and durative/stative, in most cases, the LLMs respond with more tokens in different formats, and sometimes with explanation of their choices. We use a string matching method using RegEx to map the responses to the categories, 124 Level Prompt Level 1 Does this sentence have durative aspect or stative aspect? Answer with durative or stative.\\n Sentence:\\n {sentence} Level 2 Does the verb {verb} in this sentence have durative aspect or stative aspect? Answer with durative or stative.\\n Sentence:\\n {sentence} Level 3 Does the verb {verb} in position {position} of this sentence have durative aspect or stative aspect?",
        "Answer with durative or stative.\\n Sentence:\\n {sentence} Table 2: Instruction prompt in three different constraint levels for the durative and stative aspects. Level 1 only shows the sentence, level 2 shows the sentence and the main verb of the sentence, level 3 shows the sentence, the main verb and its position of the sentence. which is commonly used in extracting LLM outputs (Argyle et al., 2023). Afterwards, we manually evaluate the coded outputs and in case of uncertain responses, we note them accordingly. 4"
      ]
    },
    {
      "section": "Results",
      "chunks": [
        "4.1 Main Results We summarize the main results of the six LLMs in Table 3 on the duration test set and the Telicity test set, as well as the performance of the finetuned model bert-large-cased as the baseline for comparison. On the duration test set, GPT-4 achieves the highest performance among the LLMs with an accuracy of 0.74 and an F1 score of 0.76. This is followed by GPT-3.5 and Llama-2, which both show comparable results in the 0.67 to 0.69 range for both metrics. The Llama-3 and Mixtral models also perform similarly with slightly lower scores. The Gemma model demonstrates the lowest performance among the LLMs with an accuracy of 0.54 and an F1 score of 0.42. Notably, the baseline large bert model significantly outperforms all LLMs, achieving an accuracy and F1 score of 0.96. On the telicity test set, GPT-4 again leads among the LLMs with an accuracy of 0.71 and an F1 score of 0.72. GPT-3.5 and Llama-3 also show strong performances with scores around the 0.65 to 0.67 range for both metrics. The Mixtral model has slightly lower scores, and Llama-2 and Gemma exhibit the lowest performance. The fine-tuning bertlarge-cased baseline still outperforms all LLMs. We show that prompting LLMs to recognize the two aspectual features in verbs results in lower performance compared to the fine-tuning baseline, which exhibits high performance. This suggests that LLMs might lack the capability to probe the deep linguistic features of given words and may require adaptation (i.e., fine-tuning) to effectively perform the task. When comparing the two aspectual features, we observe that the performance of most models is slightly lower on the telicity test set than on the duration test set, indicating that recognizing a/telic aspects is more challenging. Additionally, among the LLMs, the closed-source models (GPT3.5 and GPT-4) demonstrate better performance than the open-source models. Model Duration Telicity Acc F1 Acc F1 Gemma 0.54 0.42 0.52 0.41 GPT-3.5 0.68 0.69 0.67 0.65 GPT-4 0.74 0.76 0.71 0.72 Llama-2 0.67 0.67 0.53 0.42 Llama-3 0.64 0.63 0.65 0.65 Mixtral 0.62 0.63 0.59 0.60 bert-large-cased 0.96 0.96 0.88 0.87 Table 3: Accuracy and F1 scores for various zero-shot prompted LLMs vs. the fine-tuned baseline model bert-large-cased on duration and telicity test sets. 4.2 Verb and Verb Position Can Influence the Evaluation In this section, we analyze the impact of including the verb and its position in the sentence on the evaluation of aspectual features by LLMs in the duration and telicity test sets. we present F1 scores across three levels of prompting (sentence-only, sentence with verb, and sentence with verb and its position) in the bar plots in Figure 1 and they reveal significant insights partially.",
        "In the duration set, Gemma’s performance remains consistent across different levels of context, while GPT-3.5 and GPT-4 show substantial improvements with additional contextual information, although GPT-3.5 experiences a slight drop at the 125 Gemma GPT-3.5 GPT-4 Ilama2 Ilama3 Mistral 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 F1 Level 1 Level 2 Level 3 (a) Duration Gemma GPT-3.5 GPT-4 Ilama2 Ilama3 Mistral 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 F1 (b) Telicity Figure 1: F1 results of models in three different levels Gemma GPT-3.5 GPT-4 Ilama2 Ilama3 Mistral 0 20 40 60 80 100 False in Level 1 Correct in Level 2 False in Level 1 Correct in Level 3 Correct in Level 1 False in Level 2 Correct in Level 1 False in Level 3 (a) Duration Gemma GPT-3.5 GPT-4 Ilama2 Ilama3 Mistral 0 20 40 60 80 100 120 140 (b) Telicity Figure 2: Count of prediction differences in three different levels. The dark bars represent the count of correct predictions in level 1 which are falsely predicted in level 2&3. The light bars represent the count of false predictions in level 1 which are correctly predicted in level 2&3. highest level. Llama-2 and Llama-3 generally benefit from more context, but Llama-3’s performance slightly decreases at the highest level. Mistral demonstrates modest but consistent improvements. In the telicity set, Gemma again shows minimal variation, and GPT-3.5 and GPT-4 improve with more context, although GPT-4 has a slight decline at the highest level. Llama-2 struggles with additional context, while Llama-3 shows significant improvement. Mistral exhibits stable performance with slight gains. We further examine the count of prediction differences across the three levels for both the duration and telicity sets in Figure 2. For the duration set, models like GPT-4 and GPT-3.5 showed substantial improvements with more corrections than regressions when additional context was provided, indicating a positive impact from including the verb and its position. For instance, GPT-4 had 106 corrections at both Levels 2 and 3, compared to 25 and"
      ]
    },
    {
      "section": "24 regressions. Llama-2 and Llama-3 also benefited from the additional context, though to a lesser",
      "chunks": [
        "extent., with Llama-2 showing 94 and 107 corrections versus 66 and 62 regressions. Mistral saw steady but modest improvements, while Gemma displayed minimal changes, suggesting limited sensitivity to the added information. On the telicity set, GPT-4 and GPT-3.5 again demonstrated significant improvements with more corrections (151 and 129) than regressions (55 and 95). However, Llama-2 struggled with additional context, showing more regressions than corrections, indicating potential confusion. Llama-3 and Mistral exhibited notable but smaller benefits from the detailed prompts. Overall, our analysis underscores that while additional context including the verbs and verb positions generally enhances performance, the degree of improvement varies across models. 4.3 Error Analysis In this section, we conduct a brief analysis of certain specific error predictions we observed during inference, which are outlined in Table 4. Case 1 illustrates instances at prompt level 1, 126 Case, Input, Output Case 1, Mistral on duration set, in level1 Sentence: Should be alright then . Label: durative Output: This sentence is stative in nature. It expresses a state of being or a condition, rather than an ongoing action. The word \"\"then\"\" suggests a conclusion or a result, which is also indicative of a stative aspect. Case 2, Llama-2 on duration set, in level3 Sentence: Bake at 180 degrees of 40 - 50 minutes . Do n’t think highly too that cheese was n’t overroasted . Label: durative Output: The verb \"think\" in position 12 of the sentence does not have a durative or stative aspect. It is a stative aspect. Case 3, Gemma on telicity set Sentence: I was born here , and I was lucky enough not to get attached to any particular river . Label: telic Output (level1): The sentence is telic because the verb \"\"was born\"\" is telic and the verb \"\"get attached\"\" is also telic. Output (level2): The verb \"\"attach\"\" in this sentence has telic aspect because the verb is completed with a specific object, which is \"\"river\"\". Output (level3): The verb attached in position 13 is \"\"attach\"\". The answer is atelic. Case 4, GPT-4 on telicity set, level3 Sentence: A TV mounted above a fireplace in a nicely furnished living room . Label: telic Output: The verb \"\"mounted\"\" in position 2 in the sentence \"\"A TV mounted above a fireplace in a nicely furnished living room\"\" does not by itself convey a clear aspect because the sentence is a noun phrase, not a complete sentence with a tense that would allow us to determine aspect. Table 4: Example error cases. where the absence of verb (“be alright”) or verb position information leads the model to predict the aspect for the entire sentence, resulting in inaccurate predictions. Case 2 highlights instances of model hallucinations, where initially, the model denies the presence of probed aspects in the verb but subsequently provides an aspect in the following sentence. Case 3 demonstrates the prediction disparity across the three prompt levels.",
        "While the predictions are accurate and nuanced in the first two levels, they become nonsensical and incorrect in level 3, underscoring the model’s tendency towards hallucinations and instability. Case 4 presents a scenario where the model fails to provide an aspectual feature, incorrectly concluding that the verb lacks an aspect. These error cases underscore that employing LLMs may introduce unexpected errors due to model complexity and hallucinations. Additionally, the inconsistency of model output remains a pertinent question for further investigation. 5 Discussion & Conclusion This preliminary study evaluates the performance of various LLMs in recognizing lexical aspects, specifically duration and telicity, in zero-shot scenarios. We notice while LLMs, especially the closed-source ones (GPT-3.5 and GPT-4), are capable of recognizing the lexical aspects of verbs in sentences, they lie behind the fine-tuned baselines, indicating the potential need for further adaptation to effectively probe deep linguistic features. We conduct experiments across three levels of prompting to assess the impact of including the verb and its position in the sentence. Our results reveal that LLMs, particularly the closed-source ones, benefit from the additional context of verbs. However, this added complexity sometimes introduced regressions, indicating that while context aids comprehension, it can also pose challenges. The case analysis also introduces concerns about the complexity of hallucinations within the models. Future research could explore methods to optimize LLMs for aspectual feature recognition, such as fine-tuning LLMs or incorporating additional linguistic knowledge into model training. Currently, we only conduct the prompt in zero-shot settings, i.e. without context information. Previous work showed that prompt-based methods may underestimate the linguistic knowledge of LLMs (Hu and Levy, 2023). Therefore, we call for future exploration in different settings, such as few-shot prompting and Chain-of-Thought (CoT, Wei et al., 2023) prompting. Overall, our study offers valuable insights into the challenges and opportunities of utilizing LLMs for linguistic feature recognition. ",
        "Future research should explore data with longer texts containing more verbs and possibly provide sequential predictions on verbs within context. This would help to better understand the deeper linguistic comprehension capabilities of LLMs."
      ]
    },
        {
      "section": "Limitations",
      "chunks": [
        "The primary limitation of our preliminary work lies in the complexity and instability of LLMs, as detailed in §4.3. The models exhibit sensitivity to prompts and parameter settings. Our study tested only three curated prompts with varying information levels and observed significant variations across these conditions. Future research should delve deeper into these variations to provide explanations for these changes. Additionally, as noted in previous work (e.g., Zhang, 1995), aspectual readings are sensitive to the context surrounding the verb. Our current study tested aspectual features using a single curated dataset with individual sentences and labels."
      ]
    },
    {
      "section": "Acknowledgements",
      "chunks": [
        "The research is supported by Munich Center for Machine Learning."
      ]
    }
  ]
}